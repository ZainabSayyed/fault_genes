{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStack_Project_Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import nltk.stem \n",
    "from nltk import stem\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly select 1000 from bugslist and report (launch pad and stack over flow)\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Projects in Open-Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Project=[\"NOVA\",\"GLANCE\",\"IRONIC\",\"MAGNUM\",\"STORLETS\",\"ZUN\",\"SWIFT\",\"CINDER\",\"MANILA\",\"KARBOR\",\"FREEZER\",\n",
    "\"NEUTRON\",\"DESIGNATE\",\"DRAGONFLOW\",\"KURYR\",\"OCTAVIA\",\"TACKER\",\"TRICIRCLE\",\"TROVE\",\"SAHARA\",\"SEARCHLIGHT\",\"KEYSTONE\",\"BARBICAN\",\"CONGRESS\",\"MISTRAL\",\"HORIZON\",\"OSCLIENT (CLI)\",\"RALLY\",\"SENLIN\",\"VITRAGE\",\"WATCHER\",\"CHEF OPENSTACK\",\"KOLLA\",\"OPENSTACK CHARMS\",\"OPENSTACK-ANSIBLE\",\"PUPPET OPENSTACK\",\"TRIPLEO\",\"HEAT\",\"ZAQAR\",\"MURANO\",\"SOLUM\",\"CEILOMETER\",\"CLOUDKITTY\",\"MONASCA\",\"AODH\",\"PANKO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigned categories for OpenStack Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Category={\"COMPUTE\":[\"NOVA\",\"GLANCE\",\"IRONIC\",\"MAGNUM\",\"STORLETS\",\"ZUN\"],\"STORAGE,BACKUP AND RECOVERY\":[\"SWIFT\",\"CINDER\",\"MANILA\",\"KARBOR\",\"FREEZER\"],\"NETWORKING AND CONTENT DELIVERY\":[\"NEUTRON\",\"DESIGNATE\",\"DRAGONFLOW\",\"KURYR\",\"OCTAVIA\",\"TACKER\",\"TRICIRCLE\"],\"DATA AND ANALYTICS\":[\"TROVE\",\"SAHARA\",\"SEARCHLIGHT\"],\"SECURITY AND IDENTITY COMPLIANCE\":[\"KEYSTONE\",\"BARBICAN\",\"CONGRESS\",\"MISTRAL\"],\"MANAGEMENT TOOLS\":[\"HORIZON\",\"OSCLIENT (CLI)\",\n",
    "\"RALLY\",\"SENLIN\",\"VITRAGE\",\"WATCHER\"],\"DEPLOYMENT TOOLS\":[\"CHEF OPENSTACK\",\"KOLLA\",\"OPENSTACK CHARMS\",\"OPENSTACK-ANSIBLE\",\"PUPPET OPENSTACK\",\"TRIPLEO\"],\"APPLICATION SERVICES\":[\"HEAT\",\"ZAQAR\",\"MURANO\",\"SOLUM\"],\"MONITORING AND METERING\":[\"CEILOMETER\",\n",
    "\"CLOUDKITTY\",\"MONASCA\",\"AODH\",\"PANKO\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Project_OpenStack=[\"NOVA\",\"GLANCE\",\"IRONIC\",\"MAGNUM\",\"STORLETS\",\"ZUN\",\"SWIFT\",\"CINDER\",\"MANILA\",\"KARBOR\",\"FREEZER\",\n",
    "\"NEUTRON\",\"DESIGNATE\",\"DRAGONFLOW\",\"KURYR\",\"OCTAVIA\",\"TACKER\",\"TRICIRCLE\",\"TROVE\",\"SAHARA\",\"SEARCHLIGHT\",\"KEYSTONE\",\"BARBICAN\",\"CONGRESS\",\"MISTRAL\",\"HORIZON\",\"OSCLIENT (CLI)\",\"RALLY\",\"SENLIN\",\"VITRAGE\",\"WATCHER\",\"CHEF OPENSTACK\",\"KOLLA\",\"OPENSTACK CHARMS\",\"OPENSTACK-ANSIBLE\",\"PUPPET OPENSTACK\",\"TRIPLEO\",\"HEAT\",\"ZAQAR\",\"MURANO\",\"SOLUM\",\"CEILOMETER\",\"CLOUDKITTY\",\"MONASCA\",\"AODH\",\"PANKO\"]\n",
    "\n",
    "NOVA={}\n",
    "GLANCE={}\n",
    "IRONIC={}\n",
    "MAGNUM={}\n",
    "STORLETS={}\n",
    "ZUN={}\n",
    "SWIFT={}\n",
    "CINDER={}\n",
    "MANILA={}\n",
    "KARBOR={}\n",
    "FREEZER={}\n",
    "NEUTRON={}\n",
    "DESIGNATE={}\n",
    "DRAGONFLOW={}\n",
    "KURYR={}\n",
    "OCTAVIA={}\n",
    "TACKER={}\n",
    "TRICIRCLE={}\n",
    "TROVE={}\n",
    "SAHARA={}\n",
    "SEARCHLIGHT={}\n",
    "KEYSTONE={}\n",
    "BARBICAN={}\n",
    "CONGRESS={}\n",
    "MISTRAL={}\n",
    "HORIZON={}\n",
    "OSCLIENT={}\n",
    "RALLY={}\n",
    "SENLIN={}\n",
    "VITRAGE={}\n",
    "WATCHER={}\n",
    "CHEFOPENSTACK={}\n",
    "KOLLA={}\n",
    "OPENSTACKCHARMS={}\n",
    "OPENSTACKANSIBLE={}\n",
    "PUPPETOPENSTACK={}\n",
    "TRIPLEO={}\n",
    "HEAT={}\n",
    "ZAQAR={}\n",
    "MURANO={}\n",
    "SOLUM={}\n",
    "CEILOMETER={}\n",
    "CLOUDKITTY={}\n",
    "MONASCA={}\n",
    "AODH={}\n",
    "PANKO={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"buglist.xlsx\"\n",
    "df_launchpad=pd.read_excel(filename)\n",
    "df=pd.DataFrame(df_launchpad)\n",
    "del(df_launchpad)\n",
    "field=[]\n",
    "for i in df.project:\n",
    "    if i.upper() in Project:\n",
    "        field.append(i.upper())\n",
    "    else:\n",
    "        field.append(i.upper())\n",
    "df=df.drop(['project','component','version','fault_class','fault_type','fault_symptom','severity','priority','status','mitigation','log','repro','submitter','assignee','created','deployment'], axis=1)\n",
    "df=df.assign(Project=pd.Series(field))\n",
    "field=[]\n",
    "count=0\n",
    "for i in df.Project:\n",
    "    count=count+1\n",
    "    for k,v in Category.items():\n",
    "        if i in v:\n",
    "            field.append(k)\n",
    "            break\n",
    "    if len(field)<count:\n",
    "        field.append('Others')\n",
    "#df.set_index=df.bug\n",
    "df=df.assign(Category=pd.Series(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"ask_os.csv\"\n",
    "df_ask_os = pd.read_csv(filename)\n",
    "df_ask=pd.DataFrame(df_ask_os)\n",
    "del(df_ask_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add Project column into ask_os\n",
    "field=[]\n",
    "for i in df_ask.answer:\n",
    "    if type(i)== int or type(i)== float:  \n",
    "        continue\n",
    "    i = re.sub(r'[^\\x00-\\x7f]','',i)\n",
    "    if type(i) == type(u''):\n",
    "        i = i.encode(\"utf-8\",'ignore')\n",
    "    data=str(i).split()\n",
    "    for j in data:\n",
    "        if j.upper() in Project:\n",
    "            field.append(j.upper())\n",
    "            \n",
    "df_ask=df_ask.assign(Project=pd.Series(field))\n",
    "field=[]\n",
    "count=0\n",
    "for i in df_ask.Project:\n",
    "    count= count +1\n",
    "    for k,v in Category.items():\n",
    "        if i in v:\n",
    "            field.append(k)\n",
    "            break\n",
    "    if len(field)< count:\n",
    "        field.append('Other')\n",
    "#df.set_index=df.bug\n",
    "df_ask=df_ask.assign(Category=pd.Series(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_ask.set_index=df_ask.url\n",
    "df_ask=df_ask.drop(['answer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"report.xlsx\"\n",
    "df_stackoverflow = pd.read_excel(filename)\n",
    "df_st=pd.DataFrame(df_stackoverflow)\n",
    "del(df_stackoverflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field=[]\n",
    "for i in df_st.Project:\n",
    "    if i.upper() in Project:\n",
    "        field.append(i.upper())\n",
    "df_st=df_st.drop(['Project','answers','link','date','votes','fetch_url'],axis=1)\n",
    "df_st=df_st.assign(Project=pd.Series(field))\n",
    "#df_st.set_index=df_st.id\n",
    "field=[]\n",
    "count=0\n",
    "for i in df_ask.Project:\n",
    "    count = count + 1\n",
    "    for k,v in Category.items():\n",
    "        if i in v:\n",
    "            field.append(k)\n",
    "            break\n",
    "    if len(field)<count:\n",
    "        field.append('Other')\n",
    "#df.set_index=df.bug\n",
    "df_st=df_st.assign(Category=pd.Series(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "stop_word_dict=[]\n",
    "for i in stop_words:\n",
    "    stop_word_dict.append(str(i.encode(\"utf-8\")))\n",
    "common_words=['',\"aren't\",'ffffffffff','hi','Hi','hello','Hello','the']\n",
    "stop_word_dict=stop_word_dict + common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create tokens and filter out unwanted characters from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dict(dataframe,field,stop_word_dict):\n",
    "    corpus=[]\n",
    "    for i in field:\n",
    "        \n",
    "        if type(i)== int or type(i)== float:  \n",
    "            continue\n",
    "        i = re.sub(r'[^\\x00-\\x7f]','',i)\n",
    "        for k in i:\n",
    "            if type(k) == type(u''):\n",
    "                k = k.encode(\"utf-8\",'ignore')\n",
    "        corpus.append(str(i).strip())\n",
    "    dataframe['field_corpus']=pd.Series(corpus)\n",
    "    dataframe['field_corpus']=pd.Series( str(i).lower()  if len(str(i)) >0 else '' for i in dataframe.field_corpus)\n",
    "    corpus=[]\n",
    "    for i in dataframe.field_corpus:\n",
    "        data=(str(i))\n",
    "        data=re.sub(r'[^\\x00-\\x7f]','',data) or re.sub(r'[0-9]','',data)\n",
    "        corpus.append(data) \n",
    "    dataframe.field_corpus_new=pd.Series(corpus)\n",
    "    corpus=[]\n",
    "    new_corpus=[]\n",
    "    row_corpus=[]\n",
    "    for i in dataframe.field_corpus_new:\n",
    "        substr=re.split('[^A-Za-z]',i)\n",
    "        for j in substr:\n",
    "            j=j.strip()\n",
    "            if j not in stop_word_dict and len(j)>1:\n",
    "                corpus.append(ps.stem(j))   \n",
    "        new_corpus.append(corpus)\n",
    "        corpus=[]\n",
    "    dataframe.field_words_bag=pd.Series(new_corpus)\n",
    "    field_words_count={}\n",
    "    for i in new_corpus:\n",
    "        for w in i:\n",
    "            field_words_count[w]=field_words_count.get(w,0)+1 \n",
    "    return field_words_count,dataframe.field_words_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Complie and Run piece of script for each project seprately\n",
    "#For testing it's generated for only 3 project Nova, Neutron and Horizon\n",
    "#Extend script to run for all project available on Project field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fault_Details_lp= pd.Series(df.fault_description+df.req)\n",
    "#df=df.drop(['fault_description','req'],axis=1)\n",
    "df=df.assign(Fault_Details_lp=Fault_Details_lp.values)\n",
    "launchpad_words_count={}\n",
    "launchpad_words_count,df['field_words_bag']=create_dict(df,df.Fault_Details_lp,stop_word_dict)\n",
    "#df=df.drop(['Fault_Details_lp'],axis=1)\n",
    "for j in range(0,len(df)):\n",
    "    if df.Project[j] == 'HORIZON':\n",
    "        for k in df.field_words_bag[j]:\n",
    "            HORIZON[k]=HORIZON.get(k,0)+1 \n",
    "'''\n",
    "my_words_count={}\n",
    "for k,v in launchpad_words_count.items():\n",
    "    my_words_count[k]=my_words_count.get(k,1)+v '''\n",
    "del(launchpad_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fault_Details_st= pd.Series(df_st.title+df_st.tags+ df_st.longtext.to_string())\n",
    "#df_st=df_st.drop(['tags','title','longtext'],axis=1)\n",
    "df_st=df_st.assign(Fault_Details_st=Fault_Details_st.values)\n",
    "stackoverflow_words_count={}\n",
    "stackoverflow_words_count,df_st['field_words_bag']=create_dict(df_st,df_st.Fault_Details_st,stop_word_dict)\n",
    "#df_st=df_st.drop(['Fault_Details_st'],axis=1)\n",
    "'''for k,v in stackoverflow_words_count.items():\n",
    "    my_words_count[k]=my_words_count.get(k,1)+v'''\n",
    "for j in range(0,len(df_st)):\n",
    "    if df_st.Project[j] == 'HORIZON':\n",
    "        for k in df_st.field_words_bag[j]:\n",
    "            HORIZON[k]=HORIZON.get(k,0)+1\n",
    "del(stackoverflow_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fault_Details_ask = pd.Series(df_ask.summary+df_ask.title)\n",
    "#df_ask=df_ask.drop(['summary','title'],axis=1)\n",
    "df_ask=df_ask.assign(Fault_Details_ask=Fault_Details_ask.values)\n",
    "ask_words_count={}\n",
    "ask_words_count,df_ask['field_words_bag']=create_dict(df_ask,df_ask.Fault_Details_ask,stop_word_dict)\n",
    "#df_ask=df_ask.drop(['Fault_Details_ask'],axis=1)\n",
    "'''for k,v in ask_words_count.items():\n",
    "    my_words_count[k]=my_words_count.get(k,1)+v'''\n",
    "for j in range(0,len(df_ask)):\n",
    "    if df_ask.Project[j] == 'HORIZON':\n",
    "        for k in df_ask.field_words_bag[j]:\n",
    "            HORIZON[k]=HORIZON.get(k,0)+1\n",
    "del(ask_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create combined unique wordlist from all 3 data scources for each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for key, value in sorted(HORIZON.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "df_wordcount=pd.DataFrame(mylist, columns =['Key','Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wordcount.to_csv('dictionary_HORIZON.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HORIZON_mydict=set(df_wordcount.Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"dictionary created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del (df_wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Topic Modeling: This script loads a gensim dictionary and associated corpus and applies an LDA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html\"> Topic Modeling for Fun and Profit </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models , similarities\n",
    "import pyLDAvis.gensim\n",
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build Dictinoary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts= \"open_stack\"\n",
    "dictionary_HORIZON = corpora.Dictionary([HORIZON_mydict])\n",
    "dictionary_HORIZON.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save dictionary for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary_HORIZON.save(\"open_stack_HORIZON.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_HORIZON =[dictionary_HORIZON.doc2bow(df.field_words_bag.loc[i]) for i in range(0,len(df)) if df.Project[i]== 'HORIZON'] \n",
    "corpus_HORIZON = corpus_HORIZON + [dictionary_HORIZON.doc2bow(df_st.field_words_bag.loc[i]) for i in range(0,len(df_st)) if df_st.Project[i]== 'HORIZON'] \n",
    "corpus_HORIZON = corpus_HORIZON +[dictionary_HORIZON.doc2bow(df_ask.field_words_bag.loc[i]) for i in range(0,len(df_ask)) if df_ask.Project[i]== 'HORIZON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save corpus for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize(\"open_stack_HORIZON.mm\", corpus_HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the corpus and Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_HORIZON = corpora.MmCorpus(\"open_stack_HORIZON.mm\")\n",
    "dictionary_HORIZON = corpora.Dictionary.load(\"open_stack_HORIZON.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics,passes,alpha=5,20,0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_HORIZON = models.LdaModel(corpus_HORIZON, id2word=dictionary_HORIZON,\n",
    "                        num_topics=num_topics,\n",
    "                        passes=passes,\n",
    "                        alpha =alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save lda results for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_HORIZON.save(\"open_stack_HORIZON.lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_HORIZON=models.LdaModel.load('open_stack_HORIZON.lda',mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words_HORIZON = [[word for word in lda_HORIZON.show_topic(topicno, topn=5)] for topicno in range(5)]\n",
    "for i in top_words_HORIZON:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First LDA model with 5 topics, 20 passes, alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "openstack_data_HORIZON =  pyLDAvis.gensim.prepare(lda_HORIZON, corpus_HORIZON, dictionary_HORIZON)\n",
    "pyLDAvis.display(openstack_data_HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(openstack_data_HORIZON,\"openstack_HORIZON.html\")\n",
    "#pyLDAvis.save_html(vis_data,outpth+'LDA_Visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wordcount.to_csv('dictionary_NEUTRON.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wordcount.to_csv('dictionary_HORIZON.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lda_HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_table=pd.DataFrame(openstack_data_HORIZON.token_table)\n",
    "token_table.to_csv(\"open_stack_token_table_HORIZON.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assign cluster no with highest probability to each record (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in df.field_words_bag:\n",
    "    bow_vector = dictionary.doc2bow(i)\n",
    "    lda_vector = lda[bow_vector]\n",
    "    lda_vector=sorted(lda_vector, key=lambda x: x[1],reverse=True)\n",
    "    topic.append(lda_vector[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Cluster']=pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write dataset with Cluster no to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in df_st.field_words_bag:\n",
    "    bow_vector = dictionary.doc2bow(i)\n",
    "    lda_vector = lda[bow_vector]\n",
    "    lda_vector=sorted(lda_vector, key=lambda x: x[1],reverse=True)\n",
    "    topic.append(lda_vector[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_st['Cluster']=pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_st.to_csv('df_st.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in df_ask.field_words_bag:\n",
    "    bow_vector = dictionary.doc2bow(i)\n",
    "    lda_vector = lda[bow_vector]\n",
    "    lda_vector=sorted(lda_vector, key=lambda x: x[1],reverse=True)\n",
    "    topic.append(lda_vector[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ask['Cluster']=pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ask.to_csv('df_ask.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "summary": "ML_FaultGenes",
   "url": "https://anaconda.org/zainabsayyed/openstack_ml"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
