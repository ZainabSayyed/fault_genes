{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStack_WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import nltk.stem \n",
    "from nltk import stem\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly select 1000 from bugslist and report (launch pad and stack over flow)\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"buglist.xlsx\"\n",
    "df_launchpad=pd.read_excel(filename)\n",
    "df=pd.DataFrame(df_launchpad)\n",
    "del(df_launchpad)\n",
    "df.set_index=df.bug\n",
    "df=df.drop(['project','component','version','fault_class','fault_type','fault_symptom','severity','priority','status','mitigation','log','repro','submitter','assignee','created','deployment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17326"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = \"ask_os.csv\"\n",
    "df_ask_os = pd.read_csv(filename)\n",
    "df_ask=pd.DataFrame(df_ask_os)\n",
    "del(df_ask_os)\n",
    "df_ask.set_index=df_ask.url\n",
    "df_ask=df_ask.drop(['Serial','answer'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"report.xlsx\"\n",
    "df_stackoverflow = pd.read_excel(filename)\n",
    "\n",
    "df_st=pd.DataFrame(df_stackoverflow)\n",
    "del(df_stackoverflow)\n",
    "df_st.set_index=df_st.id\n",
    "df_st=df_st.drop(['answers','link','Creator','date','votes','fetch_url'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "stop_word_dict=[]\n",
    "for i in stop_words:\n",
    "    stop_word_dict.append(str(i.encode(\"utf-8\")))\n",
    "common_words=['',\"aren't\",'ffffffffff']\n",
    "stop_word_dict=stop_word_dict + common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dict(dataframe,field,stop_word_dict):\n",
    "    corpus=[]\n",
    "    for i in field:\n",
    "        \n",
    "        if type(i)== int or type(i)== float:  \n",
    "            continue\n",
    "        i = re.sub(r'[^\\x00-\\x7f]','',i)\n",
    "        for k in i:\n",
    "            if type(k) == type(u''):\n",
    "                k = k.encode(\"utf-8\",'ignore')\n",
    "        corpus.append(str(i).strip())\n",
    "    dataframe['field_corpus']=pd.Series(corpus)\n",
    "    dataframe['field_corpus']=pd.Series( str(i).lower()  if len(str(i)) >0 else '' for i in dataframe.field_corpus)\n",
    "    corpus=[]\n",
    "    for i in dataframe.field_corpus:\n",
    "        data=(str(i))\n",
    "        data=re.sub(r'[^\\x00-\\x7f]','',data) or re.sub(r'[0-9]','',data)\n",
    "        corpus.append(data) \n",
    "    dataframe.field_corpus_new=pd.Series(corpus)\n",
    "    corpus=[]\n",
    "    new_corpus=[]\n",
    "    row_corpus=[]\n",
    "    for i in dataframe.field_corpus_new:\n",
    "        substr=re.split('[^A-Za-z]',i)\n",
    "        for j in substr:\n",
    "            j=j.strip()\n",
    "            if j not in stop_word_dict and len(j)>1:\n",
    "                corpus.append(ps.stem(j))   \n",
    "        new_corpus.append(corpus)\n",
    "        corpus=[]\n",
    "    dataframe.field_words_bag=pd.Series(new_corpus)\n",
    "    field_words_count={}\n",
    "    for i in new_corpus:\n",
    "        for w in i:\n",
    "            field_words_count[w]=field_words_count.get(w,0)+1 \n",
    "    return field_words_count,dataframe.field_words_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_words_count={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Fault_Details_lp= pd.Series(df.fault_description+df.req)\n",
    "#df=df.drop(['fault_description','req'],axis=1)\n",
    "df=df.assign(Fault_Details_lp=Fault_Details_lp.values)\n",
    "launchpad_words_count={}\n",
    "launchpad_words_count,df['field_words_bag']=create_dict(df,df.Fault_Details_lp,stop_word_dict)\n",
    "#df=df.drop(['Fault_Details_lp'],axis=1)\n",
    "for k,v in launchpad_words_count.items():\n",
    "    my_words_count[k]=my_words_count.get(k,1)+v\n",
    "del(launchpad_words_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31659"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Fault_Details_st= pd.Series(df_st.title+df_st.tags+ df_st.longtext.to_string())\n",
    "#df_st=df_st.drop(['tags','title','longtext'],axis=1)\n",
    "df_st=df_st.assign(Fault_Details_st=Fault_Details_st.values)\n",
    "stackoverflow_words_count={}\n",
    "stackoverflow_words_count,df_st['field_words_bag']=create_dict(df_st,df_st.Fault_Details_st,stop_word_dict)\n",
    "#df_st=df_st.drop(['Fault_Details_st'],axis=1)\n",
    "for k,v in stackoverflow_words_count.items():\n",
    "    my_words_count[k]=my_words_count.get(k,1)+v\n",
    "del(stackoverflow_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fault_Details_ask = pd.Series(df_ask.summary+df_ask.title)\n",
    "#df_ask=df_ask.drop(['summary','title'],axis=1)\n",
    "df_ask=df_ask.assign(Fault_Details_ask=Fault_Details_ask.values)\n",
    "ask_words_count={}\n",
    "ask_words_count,df_ask['field_words_bag']=create_dict(df_ask,df_ask.Fault_Details_ask,stop_word_dict)\n",
    "#df_ask=df_ask.drop(['Fault_Details_ask'],axis=1)\n",
    "for k,v in ask_words_count.items():\n",
    "    my_words_count[k]=my_words_count.get(k,1)+v\n",
    "del(ask_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>Fault_Details_ask</th>\n",
       "      <th>field_corpus</th>\n",
       "      <th>field_words_bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Hi \\nam trying to install Magnum-api and ma...</td>\n",
       "      <td>Unable to locate package Magnum-api</td>\n",
       "      <td>https://ask.openstack.org/en/question/103555/u...</td>\n",
       "      <td>&lt;p&gt;Hi \\nam trying to install Magnum-api and ma...</td>\n",
       "      <td>&lt;p&gt;hi \\nam trying to install magnum-api and ma...</td>\n",
       "      <td>[hi, tri, instal, magnum, api, magnum, conduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;Hello\\nbased with these documentation\\nhttp...</td>\n",
       "      <td>detailed documentation how to install Mitaka w...</td>\n",
       "      <td>https://ask.openstack.org/en/question/103553/d...</td>\n",
       "      <td>&lt;p&gt;Hello\\nbased with these documentation\\nhttp...</td>\n",
       "      <td>&lt;p&gt;hello\\nbased with these documentation\\nhttp...</td>\n",
       "      <td>[hello, base, document, http, doc, openstack, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div class=\"snippet\"&gt;&lt;p&gt;These controller nodes...</td>\n",
       "      <td>Galera breaks then all the controllers go down</td>\n",
       "      <td>https://ask.openstack.org/en/question/103510/g...</td>\n",
       "      <td>&lt;div class=\"snippet\"&gt;&lt;p&gt;These controller nodes...</td>\n",
       "      <td>&lt;div class=\"snippet\"&gt;&lt;p&gt;these controller nodes...</td>\n",
       "      <td>[div, class, snippet, control, node, reboot, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Hi, i'm now including new compute nodes to ...</td>\n",
       "      <td>Run kolla-ansible bootstrap-servers to specifi...</td>\n",
       "      <td>https://ask.openstack.org/en/question/103552/r...</td>\n",
       "      <td>&lt;p&gt;Hi, i'm now including new compute nodes to ...</td>\n",
       "      <td>&lt;p&gt;hi, i'm now including new compute nodes to ...</td>\n",
       "      <td>[hi, includ, new, comput, node, exist, opensta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;Hi all,&lt;/p&gt;\\n\\n&lt;p&gt;I am new to OpenStack Hea...</td>\n",
       "      <td>How to use heat template to create MySQL serve...</td>\n",
       "      <td>https://ask.openstack.org/en/question/103384/h...</td>\n",
       "      <td>&lt;p&gt;Hi all,&lt;/p&gt;\\n\\n&lt;p&gt;I am new to OpenStack Hea...</td>\n",
       "      <td>&lt;p&gt;hi all,&lt;/p&gt;\\n\\n&lt;p&gt;i am new to openstack hea...</td>\n",
       "      <td>[hi, new, openstack, heat, would, like, use, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  <p>Hi \\nam trying to install Magnum-api and ma...   \n",
       "1  <p>Hello\\nbased with these documentation\\nhttp...   \n",
       "2  <div class=\"snippet\"><p>These controller nodes...   \n",
       "3  <p>Hi, i'm now including new compute nodes to ...   \n",
       "4  <p>Hi all,</p>\\n\\n<p>I am new to OpenStack Hea...   \n",
       "\n",
       "                                               title  \\\n",
       "0                Unable to locate package Magnum-api   \n",
       "1  detailed documentation how to install Mitaka w...   \n",
       "2     Galera breaks then all the controllers go down   \n",
       "3  Run kolla-ansible bootstrap-servers to specifi...   \n",
       "4  How to use heat template to create MySQL serve...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://ask.openstack.org/en/question/103555/u...   \n",
       "1  https://ask.openstack.org/en/question/103553/d...   \n",
       "2  https://ask.openstack.org/en/question/103510/g...   \n",
       "3  https://ask.openstack.org/en/question/103552/r...   \n",
       "4  https://ask.openstack.org/en/question/103384/h...   \n",
       "\n",
       "                                   Fault_Details_ask  \\\n",
       "0  <p>Hi \\nam trying to install Magnum-api and ma...   \n",
       "1  <p>Hello\\nbased with these documentation\\nhttp...   \n",
       "2  <div class=\"snippet\"><p>These controller nodes...   \n",
       "3  <p>Hi, i'm now including new compute nodes to ...   \n",
       "4  <p>Hi all,</p>\\n\\n<p>I am new to OpenStack Hea...   \n",
       "\n",
       "                                        field_corpus  \\\n",
       "0  <p>hi \\nam trying to install magnum-api and ma...   \n",
       "1  <p>hello\\nbased with these documentation\\nhttp...   \n",
       "2  <div class=\"snippet\"><p>these controller nodes...   \n",
       "3  <p>hi, i'm now including new compute nodes to ...   \n",
       "4  <p>hi all,</p>\\n\\n<p>i am new to openstack hea...   \n",
       "\n",
       "                                     field_words_bag  \n",
       "0  [hi, tri, instal, magnum, api, magnum, conduct...  \n",
       "1  [hello, base, document, http, doc, openstack, ...  \n",
       "2  [div, class, snippet, control, node, reboot, s...  \n",
       "3  [hi, includ, new, comput, node, exist, opensta...  \n",
       "4  [hi, new, openstack, heat, would, like, use, s...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57449"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_words_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove non-ascii character to process data using NLTK\n",
    "#NLTK coverts string into meaningful words called token, removes punctuations and special characters.\n",
    "#Analyzing Fault_desc and Req field from data set\n",
    "#write process data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#launchpad_words_count={}\n",
    "#launchpad_words_count,df['field_words_bag']=create_dict(df,df.Fault_Details_lp,stop_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for key, value in sorted(my_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "df_wordcount=pd.DataFrame(mylist, columns =['Key','Count'])\n",
    "#del (mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del (my_words_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57449"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wordcount.to_csv('dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary created\n"
     ]
    }
   ],
   "source": [
    "print \"dictionary created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydict=set(df_wordcount.Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del (df_wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Topic Modeling: This script loads a gensim dictionary and associated corpus and applies an LDA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html\"> Topic Modeling for Fun and Profit </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaina\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models , similarities\n",
    "import pyLDAvis.gensim\n",
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build Dictinoary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts= \"open_stack\"\n",
    "dictionary = corpora.Dictionary([mydict])\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: \n",
      "Dictionary(57679 unique tokens: [u'swdhome', u'htmlaccident', u'mjflmwmilcaichvibgljvvjmijogimh', u'pkmgksasi', u'ozfho']...)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary: \")\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save dictionary for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary.save(\"open_stack.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus =[dictionary.doc2bow(df.field_words_bag.loc[i]) for i in range(0,len(df))] \n",
    "corpus= corpus + [dictionary.doc2bow(df_st.field_words_bag.loc[i]) for i in range(0,len(df_st))] \n",
    "corpus= corpus +[dictionary.doc2bow(df_ask.field_words_bag.loc[i]) for i in range(0,len(df_ask))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save corpus for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize(\"open_stack.mm\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the corpus and Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = corpora.MmCorpus(\"open_stack.mm\")\n",
    "dictionary = corpora.Dictionary.load(\"open_stack.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics,passes,alpha=5,20,0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus, id2word=dictionary,\n",
    "                        num_topics=num_topics,\n",
    "                        passes=passes,\n",
    "                        alpha =alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save lda results for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.save(\"open_stack.lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda=models.LdaModel.load('open_stack.lda',mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'network', 0.020525661313409882), (u'code', 0.015209313647057266), (u'instanc', 0.012569376822856731), (u'node', 0.012553155741632153), (u'ip', 0.012090819308485282)]\n",
      "[(u'openstack', 0.063726644864840504), (u'nova', 0.02449840633981323), (u'instal', 0.02430762270872705), (u'use', 0.023819859593658094), (u'tri', 0.022004846871574484)]\n",
      "[(u'test', 0.019880705481180518), (u'openstack', 0.01851822476394208), (u'org', 0.018370467322106426), (u'https', 0.017524987717491385), (u'instal', 0.014228456575570857)]\n",
      "[(u'nova', 0.058013282028327548), (u'py', 0.035673376152863152), (u'lib', 0.033724454272338639), (u'file', 0.032581795241183091), (u'usr', 0.032238469524396941)]\n",
      "[(u'http', 0.020794664768736822), (u'keyston', 0.017271553209166034), (u'swift', 0.015510824756368601), (u'code', 0.015059128068668782), (u'auth', 0.012924926325462093)]\n"
     ]
    }
   ],
   "source": [
    "top_words = [[word for word in lda.show_topic(topicno, topn=5)] for topicno in range(5)]\n",
    "for i in top_words:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First LDA model with 5 topics, 20 passes, alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "openstack_data =  pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.display(openstack_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(openstack_data,\"openstack.html\")\n",
    "#pyLDAvis.save_html(vis_data,outpth+'LDA_Visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=57679, num_topics=5, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "print(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_table=pd.DataFrame(openstack_data.token_table )\n",
    "token_table.to_csv(\"open_stack_token_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in df.field_words_bag:\n",
    "    bow_vector = dictionary.doc2bow(i)\n",
    "    lda_vector = lda[bow_vector]\n",
    "    lda_vector=sorted(lda_vector, key=lambda x: x[1],reverse=True)\n",
    "    topic.append(lda_vector[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Cluster']=pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in df_st.field_words_bag:\n",
    "    bow_vector = dictionary.doc2bow(i)\n",
    "    lda_vector = lda[bow_vector]\n",
    "    lda_vector=sorted(lda_vector, key=lambda x: x[1],reverse=True)\n",
    "    topic.append(lda_vector[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_st['Cluster']=pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_st.to_csv('df_st.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in df_ask.field_words_bag:\n",
    "    bow_vector = dictionary.doc2bow(i)\n",
    "    lda_vector = lda[bow_vector]\n",
    "    lda_vector=sorted(lda_vector, key=lambda x: x[1],reverse=True)\n",
    "    topic.append(lda_vector[0][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ask['Cluster']=pd.Series(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ask.to_csv('df_ask.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "summary": "ML_FaultGenes",
   "url": "https://anaconda.org/zainabsayyed/openstack_ml"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
